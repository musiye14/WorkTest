from .state import InterviewState
from ..prompt.prompt import *
from ..llms.base import BaseLLM
from ..utils.logger import log_node_content, log_token_usage, logger
from typing import Dict, Any
from langchain_core.messages import HumanMessage,AIMessage
import time


class InterviewNodes:
    """é¢è¯•èŠ‚ç‚¹ç±»ï¼Œå°è£…æ‰€æœ‰èŠ‚ç‚¹é€»è¾‘"""

    def __init__(self, llm: BaseLLM, think_max_num: int = 3, deep_question_max_num: int = 3, agent_name: str = "InterviewAgent"):
        """
        åˆå§‹åŒ–é¢è¯•èŠ‚ç‚¹

        Args:
            llm: LLM å®ä¾‹
            think_max_num: æ€è€ƒæœ€å¤§è½®æ¬¡ï¼Œé»˜è®¤ 3
            deep_question_max_num: è¿½é—®æœ€å¤§æ¬¡æ•°ï¼Œé»˜è®¤ 3
            agent_name: Agent åç§°ï¼Œç”¨äºæ—¥å¿—è®°å½•
        """
        self.llm = llm
        self.think_max_num = think_max_num
        self.deep_question_max_num = deep_question_max_num
        self.agent_name = agent_name

    def message_input(self, state: InterviewState) -> Dict[str, Any]:
        """è¾“å…¥å¤„ç†èŠ‚ç‚¹"""
        return {
            "interview_stage": "questionBuild",
            "thinking_process": [],
            "deep_index": 0
        }

    def question_build(self, state: InterviewState) -> Dict[str, Any]:
        """é—®é¢˜ç”ŸæˆèŠ‚ç‚¹"""
        # è·å–ä¸Šä¸€è½®çš„åé¦ˆï¼ˆå¦‚æœæœ‰ï¼‰
        reflection_feedback = state.get("reflection_result", {})
        improvement_suggestions = reflection_feedback.get("improvement_suggestions", [])

        # å¦‚æœæœ‰åé¦ˆï¼Œä½¿ç”¨å¸¦åé¦ˆçš„æç¤ºè¯ï¼›å¦åˆ™ä½¿ç”¨æ™®é€šæç¤ºè¯
        if improvement_suggestions:
            feedback_text = "\n".join([f"- {s}" for s in improvement_suggestions])
            prompt = QUESTION_PLAN_GENERATION_WITH_FEEDBACK_PROMPT.format(
                resume=state["resume_info"],
                jd=state["jd_info"],
                mode=state["mode"],
                difficulty=state["difficulty"],
                previous_attempt=state.get("question_plan", []),
                feedback=feedback_text
            )
        else:
            prompt = QUESTION_PLAN_GENERATION_PROMPT.format(
                resume=state["resume_info"],
                jd=state["jd_info"],
                mode=state["mode"],
                difficulty=state["difficulty"]
            )

        result = self.llm.invoke_with_schema(prompt, output_schema_question_plan_generation, node_name="questionBuild")
        return {"question_plan": result["question_plan"]}

    def think(self, state: InterviewState) -> Dict[str, Any]:
        """æ·±åº¦æ€è€ƒèŠ‚ç‚¹ï¼Œæ ¹æ® interview_stage é€‰æ‹©å¯¹åº”çš„æ·±åº¦æ€è€ƒæç¤ºè¯"""
        round_num = len(state["thinking_process"]) + 1
        stage = state["interview_stage"]

        if stage == "questionBuild":
            prompt = DEEP_THINKING_PROMPT_QUESTION_BUILD.format(
                resume=state["resume_info"],
                jd=state["jd_info"],
                mode=state["mode"],
                difficulty=state["difficulty"],
                round=round_num
            )
        elif stage == "adjustQuestion":
            prompt = DEEP_THINKING_PROMPT_ADJUST_QUESTION.format(
                questions_plan=state["question_plan"],
                completed_questions=state.get("completed_questions", []),
                performance_analysis=state.get("performance_analysis", ""),
                weak_points=state.get("weak_points", []),
                strong_points=state.get("strong_points", []),
                round=round_num
            )
        elif stage == "deepQuestion":
            # è·å–ç”¨æˆ·å›ç­”å†…å®¹
            user_answer = ""
            if state["messages"]:
                last_msg = state["messages"][-1]
                if isinstance(last_msg, HumanMessage):
                    user_answer = last_msg.content

            prompt = DEEP_THINKING_PROMPT_DEEP_QUESTION.format(
                current_question=state["current_question"],
                user_answer=user_answer,
                answer_analysis=state.get("answer_analysis", ""),
                follow_up_count=state["deep_index"],
                difficulty=state["difficulty"],
                round=round_num
            )
        else:
            raise ValueError(f"æœªçŸ¥çš„ interview_stage: {stage}")

        result = self.llm.invoke_with_schema(prompt, output_schema_deep_thinking, node_name=f"{stage}Think")
        return {
            "thinking_result": result,
            "thinking_process": state["thinking_process"] + [result]
        }

    def judge(self, state: InterviewState) -> Dict[str, Any]:
        """åæ€åˆ¤æ–­èŠ‚ç‚¹ï¼Œæ ¹æ® interview_stage é€‰æ‹©å¯¹åº”çš„åæ€æç¤ºè¯"""
        thinking_process = state["thinking_process"]
        round_num = len(thinking_process)
        stage = state["interview_stage"]

        if stage == "questionBuild":
            prompt = REFLECTION_PROMPT_QUESTION_BUILD.format(
                draft_question_plan=state["question_plan"],
                thinking_process=state["thinking_process"],
                resume=state["resume_info"],
                jd=state["jd_info"],
                difficulty=state["difficulty"],
                round=round_num
            )
        elif stage == "adjustQuestion":
            prompt = REFLECTION_PROMPT_ADJUST_QUESTION.format(
                adjusted_question_plan=state["question_plan"],
                original_question_plan=state.get("original_question_plan", []),
                thinking_process=state["thinking_process"],
                performance_analysis=state.get("performance_analysis", ""),
                round=round_num
            )
        elif stage == "deepQuestion":
            # è·å–ç”¨æˆ·å›ç­”å†…å®¹
            user_answer = ""
            if state["messages"]:
                last_msg = state["messages"][-1]
                if isinstance(last_msg, HumanMessage):
                    user_answer = last_msg.content

            prompt = REFLECTION_PROMPT_DEEP_QUESTION.format(
                draft_deep_question=state.get("current_question", {}),
                thinking_process=state["thinking_process"],
                current_question=state["current_question"],
                user_answer=user_answer,
                follow_up_count=state["deep_index"],
                round=round_num
            )
        else:
            raise ValueError(f"æœªçŸ¥çš„ interview_stage: {stage}")

        result = self.llm.invoke_with_schema(prompt, output_schema_reflection, node_name=f"{stage}Judge")

        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§è½®æ¬¡é™åˆ¶
        if round_num >= self.think_max_num:
            # è¶…è¿‡é™åˆ¶,å¼ºåˆ¶é€šè¿‡(å³ä½¿è´¨é‡ä¸å¤Ÿå¥½)
            print(f"[è­¦å‘Š] æ€è€ƒè½®æ¬¡å·²è¾¾ä¸Šé™ ({round_num}/{self.think_max_num}),å¼ºåˆ¶é€šè¿‡")
            result["should_regenerate"] = False
            # æ·»åŠ è¯´æ˜åˆ°æ”¹è¿›å»ºè®®ä¸­
            if "improvement_suggestions" not in result:
                result["improvement_suggestions"] = []
            result["improvement_suggestions"].append(
                f"å·²è¾¾åˆ°æœ€å¤§æ€è€ƒè½®æ¬¡ ({self.think_max_num}),å¼ºåˆ¶é€šè¿‡å½“å‰ç»“æœ"
            )
            thinking_process = []


        return {"reflection_result": result, "thinking_process":thinking_process}

    def question_output(self, state: InterviewState) -> Dict[str, Any]:
        """æé—®è¾“å‡ºèŠ‚ç‚¹ - ä»é—®é¢˜åˆ—è¡¨ä¸­å–å‡ºå½“å‰é—®é¢˜å¹¶è¾“å‡º"""
        node_logger = logger.bind(agent=self.agent_name, node="questionOutput")

        question_plan = state.get("question_plan", [])
        main_question_index = state.get("main_question_index",0)

        # ç¬¬ä¸€æ¬¡è¾“å‡ºæ—¶ï¼Œæ‰“å°å®Œæ•´çš„é—®é¢˜åˆ—è¡¨
        if main_question_index == 0 and question_plan:
            print("\n" + "=" * 50)
            print(f"ğŸ“‹ æœ€ç»ˆç”Ÿæˆçš„é—®é¢˜åˆ—è¡¨ï¼ˆå…± {len(question_plan)} ä¸ªé—®é¢˜ï¼‰")
            print("=" * 50)
            node_logger.info(f"ç”Ÿæˆé—®é¢˜åˆ—è¡¨ï¼Œå…± {len(question_plan)} ä¸ªé—®é¢˜")
            for idx, q in enumerate(question_plan, 1):
                print(f"{idx}. [{q.get('difficulty', 'æœªçŸ¥')}] {q.get('topic', 'æœªçŸ¥ä¸»é¢˜')}")
                print(f"   é—®é¢˜: {q.get('question', '')}")
                print(f"   ç†ç”±: {q.get('reasoning', '')}")
                print()
            print("=" * 50 + "\n")

        # å¦‚æœè¿˜æœ‰é—®é¢˜æœªæé—®
        if main_question_index < len(question_plan):
            current_question = question_plan[main_question_index]
            main_question_index+=1

            question_text = current_question.get('question', '')
            print(f"é¢è¯•å®˜ï¼š{question_text}")

            # è®°å½•é—®é¢˜è¾“å‡º
            node_logger.info(f"è¾“å‡ºç¬¬ {main_question_index} ä¸ªé—®é¢˜: {question_text}")

            return {
                "current_question": current_question,
                "main_question_index": main_question_index,
                "messages": [AIMessage(content=current_question["question"])]
            }
        else:
            # æ‰€æœ‰é—®é¢˜å·²é—®å®Œ
            node_logger.info("æ‰€æœ‰é—®é¢˜å·²é—®å®Œï¼Œå‡†å¤‡ç»“æŸé¢è¯•")
            return {"next_step": "end"}

    def deep_question_output(self, state: InterviewState) -> Dict[str, Any]:
        """è¿½é—®è¾“å‡ºèŠ‚ç‚¹ - è¾“å‡ºè¿½é—®é—®é¢˜ç»™ç”¨æˆ·"""
        node_logger = logger.bind(agent=self.agent_name, node="deepQuestionOutput")

        current_question = state.get("current_question", {})
        follow_up_question = current_question.get("question", "")

        print(f"é¢è¯•å®˜ï¼š{follow_up_question}")

        # è®°å½•è¿½é—®è¾“å‡º
        deep_index = state.get("deep_index", 0)
        node_logger.info(f"è¾“å‡ºè¿½é—® (ç¬¬ {deep_index} æ¬¡): {follow_up_question}")

        return {
            "messages": [AIMessage(content=follow_up_question)]
        }

    def user_input(self, state: InterviewState) -> Dict[str, Any]:
        """ç­‰å¾…ç”¨æˆ·è¾“å…¥èŠ‚ç‚¹"""
        node_logger = logger.bind(agent=self.agent_name, node="userInput")

        user_answer = input("ä½ çš„å›ç­”ï¼š").strip()

        # è®°å½•ç”¨æˆ·è¾“å…¥
        node_logger.info(f"ç”¨æˆ·å›ç­”: {user_answer}")

        return {
            "messages": [HumanMessage(content=user_answer)]
        }

    def next_step(self, state: InterviewState) -> Dict[str, Any]:
        """å†³ç­–ä¸‹ä¸€æ­¥èŠ‚ç‚¹ - åˆ†æç”¨æˆ·å›ç­”å¹¶å†³å®šä¸‹ä¸€æ­¥åŠ¨ä½œ"""
        # è·å–æœ€æ–°çš„ç”¨æˆ·å›ç­”
        messages = state.get("messages", [])
        if not messages:
            return {"next_step": "end"}

        last_message = messages[-1]

        # æ£€æŸ¥æ˜¯å¦æ˜¯ç”¨æˆ·æ¶ˆæ¯
        if not isinstance(last_message, HumanMessage):
            return {"next_step": "end"}

        user_answer = last_message.content
        current_question = state.get("current_question", {})
        deep_index = state.get("deep_index", 0)

        # è°ƒç”¨ LLM åˆ¤æ–­æ˜¯å¦éœ€è¦è¿½é—®
        prompt = FOLLOW_UP_DECISION_PROMPT.format(
            current_question=current_question.get("question", ""),
            user_answer=user_answer,
            answer_analysis="",  # å¯ä»¥æ·»åŠ å›ç­”åˆ†æé€»è¾‘
            follow_up_count=deep_index
        )

        decision = self.llm.invoke_with_schema(prompt, output_schema_follow_up_decision, node_name="nextStep")

        # æ ¹æ®å†³ç­–ç»“æœè®¾ç½®ä¸‹ä¸€æ­¥
        if decision.get("should_follow_up", False)==True and deep_index < self.deep_question_max_num:
            # éœ€è¦è¿½é—®
            return {
                "next_step": "deepQuestion",
                "interview_stage": "deepQuestion",
            }
        else:
            # ä¸éœ€è¦è¿½é—®ï¼Œæ£€æŸ¥æ˜¯å¦è¿˜æœ‰å‰©ä½™çš„ä¸»é—®é¢˜
            question_plan = state.get("question_plan", [])
            main_question_index = state.get("main_question_index", 0)

            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä¸»é—®é¢˜éƒ½å·²é—®å®Œ
            if main_question_index >= len(question_plan):
                # æ‰€æœ‰é—®é¢˜å·²é—®å®Œï¼Œç»“æŸé¢è¯•
                return {
                    "next_step": "end",
                    "deep_index": 0
                }
            else:
                # è¿˜æœ‰é—®é¢˜ï¼Œè¿›å…¥ä¸‹ä¸€ä¸ªé—®é¢˜
                # é‡ç½®è¿½é—®è®¡æ•°
                return {
                    "next_step": "question",
                    "deep_index": 0
                }

    def adjust_question(self, state: InterviewState) -> Dict[str, Any]:
        """è°ƒæ•´é—®é¢˜èŠ‚ç‚¹"""
        # è·å–ä¸Šä¸€è½®çš„åé¦ˆï¼ˆå¦‚æœæœ‰ï¼‰
        reflection_feedback = state.get("reflection_result", {})
        improvement_suggestions = reflection_feedback.get("improvement_suggestions", [])

        # å¦‚æœæœ‰åé¦ˆï¼Œä½¿ç”¨å¸¦åé¦ˆçš„æç¤ºè¯ï¼›å¦åˆ™ä½¿ç”¨æ™®é€šæç¤ºè¯
        if improvement_suggestions:
            feedback_text = "\n".join([f"- {s}" for s in improvement_suggestions])
            prompt = QUESTION_ADJUSTMENT_WITH_FEEDBACK_PROMPT.format(
                questions_plan=state["question_plan"],
                completed_questions=state.get("completed_questions", []),
                performance_analysis=state.get("performance_analysis", ""),
                weak_points=state.get("weak_points", []),
                strong_points=state.get("strong_points", []),
                difficulty=state["difficulty"],
                previous_attempt=state.get("question_plan", []),
                feedback=feedback_text
            )
        else:
            prompt = QUESTION_ADJUSTMENT_PROMPT.format(
                questions_plan=state["question_plan"],
                completed_questions=state.get("completed_questions", []),
                performance_analysis=state.get("performance_analysis", ""),
                weak_points=state.get("weak_points", []),
                strong_points=state.get("strong_points", []),
                difficulty=state["difficulty"]
            )

        result = self.llm.invoke_with_schema(prompt, output_schema_question_adjustment, node_name="adjustQuestion")
        return {
            "question_plan": result["adjusted_question_plan"],
            "original_question_plan": state["question_plan"]
        }

    def deep_question(self, state: InterviewState) -> Dict[str, Any]:
        """è¿½é—®ç”ŸæˆèŠ‚ç‚¹"""
        # è·å–ç”¨æˆ·å›ç­”å†…å®¹
        user_answer = ""
        if state["messages"]:
            last_msg = state["messages"][-1]
            if isinstance(last_msg, HumanMessage):
                user_answer = last_msg.content

        # è·å–ä¸Šä¸€è½®çš„åé¦ˆï¼ˆå¦‚æœæœ‰ï¼‰
        reflection_feedback = state.get("reflection_result", {})
        improvement_suggestions = reflection_feedback.get("improvement_suggestions", [])

        # å¦‚æœæœ‰åé¦ˆï¼Œä½¿ç”¨å¸¦åé¦ˆçš„æç¤ºè¯ï¼›å¦åˆ™ä½¿ç”¨æ™®é€šæç¤ºè¯
        if improvement_suggestions:
            feedback_text = "\n".join([f"- {s}" for s in improvement_suggestions])
            prompt = DEEP_QUESTION_GENERATION_WITH_FEEDBACK_PROMPT.format(
                current_question=state["current_question"],
                user_answer=user_answer,
                answer_analysis=state.get("answer_analysis", ""),
                follow_up_count=state["deep_index"],
                difficulty=state["difficulty"],
                previous_attempt=state.get("current_question", {}),
                feedback=feedback_text
            )
        else:
            prompt = DEEP_QUESTION_GENERATION_PROMPT.format(
                current_question=state["current_question"],
                user_answer=user_answer,
                answer_analysis=state.get("answer_analysis", ""),
                follow_up_count=state["deep_index"],
                difficulty=state["difficulty"]
            )

        result = self.llm.invoke_with_schema(prompt, output_schema_deep_question_generation, node_name="deepQuestion")
        return {
            "current_question": result,
            "deep_index": state["deep_index"] + 1
        }
    

    def judge_res(self, state: InterviewState) -> str:
        """åæ€åˆ¤æ–­ç»“æœè·¯ç”±"""
        reflection = state.get("reflection_result", {})
        stage = state["interview_stage"]

        if reflection.get("should_regenerate", False) == True:
            # éœ€è¦é‡æ–°ç”Ÿæˆ
            if stage == "questionBuild":
                return "questionBuild"
            elif stage == "adjustQuestion":
                return "adjustQuestion"
            elif stage == "deepQuestion":
                return "deepQuestion"
        else:
            # é€šè¿‡æ£€æŸ¥ï¼Œæ ¹æ®é˜¶æ®µè¾“å‡ºå¯¹åº”çš„é—®é¢˜
            if stage == "deepQuestion":
                return "deepQuestionOutput"
            else:
                return "questionOutput"

    def next_step_decision(self, state: InterviewState) -> str:
        """ä¸‹ä¸€æ­¥å†³ç­–è·¯ç”±"""
        next_step = state.get("next_step", "")

        if next_step == "adjustQuestion":
            return "adjustQuestion"
        elif next_step == "deepQuestion":
            return "deepQuestion"
        elif next_step == "end":
            return "end"
        else:
            return "questionOutput"

    def end(self, state: InterviewState) -> Dict[str, Any]:
        """ç»“æŸèŠ‚ç‚¹ - æ”¶é›†æœ€ç»ˆçŠ¶æ€å¹¶è¿”å›"""
        node_logger = logger.bind(agent=self.agent_name, node="end")

        print("\n" + "=" * 50)
        print("é¢è¯•ç»“æŸï¼Œæ„Ÿè°¢å‚ä¸ï¼")
        print("=" * 50)

        print("\n" + "=" * 50)
        print("ğŸ“Š é¢è¯•ç»Ÿè®¡")
        print("=" * 50)

        messages = state.get("messages", [])
        question_plan = state.get("question_plan", [])

        print(f"æ€»é—®é¢˜æ•°: {len(question_plan)}")
        print(f"å¯¹è¯è½®æ¬¡: {len(messages)}")
        print("=" * 50)

        # è®°å½•é¢è¯•ç»“æŸç»Ÿè®¡
        node_logger.info(f"é¢è¯•ç»“æŸ | æ€»é—®é¢˜æ•°: {len(question_plan)} | å¯¹è¯è½®æ¬¡: {len(messages)}")

        # è¿”å›å®Œæ•´çš„ stateï¼Œä¸åšä»»ä½•ä¿®æ”¹
        # è¿™æ · state ä¼šè¢«ä¼ é€’åˆ°æœ€ç»ˆè¾“å‡º
        return {}
